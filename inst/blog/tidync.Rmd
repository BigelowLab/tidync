---
title: "tidync package for NetCDF data"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidync)
```

The `tidync` package recently hit CRAN after a fairly long review process on [rOpenSci](https://github.com/ropensci/software-review/issues/174). In early 2018 I just wasn't sure if it was really going to be wrapped up in a neat way, but thanks to very helpful reviewers and some key insights about [obscure types](https://github.com/ropensci/tidync/issues/75#issuecomment-468064627) it was done. 

There's a tension between the **tidyverse** and **scientific array data** in R. In short it comes down to *coordinates*, array data live inside a *space* and if that is more than the rows and columns (and slices ...) of the array then there's three ways to specify them. 

* affine transform
* rectilinear transform
* curvilinear transform

If we store data in *long form* as per the tidyverse, it really expects us to not only store every variable but also *every coordinate* of the array elements. This is what leads to (sometimes angry) complaints about the efficiency and scalability of parts of the tidyverse for scientific array data. 

There are several approaches to this, and tidync tries to insert itself into the middle. 

*NB: This post is not a comprehensive introduction to NetCDF, the hope is that tidync will provide easier ways to explore your data.* 

In particular tidync exists in order to reduce the amount of plumbing code required to get to the data required. 


## NetCDF

NetCDF is a very widely used file format for storing array-based data as
*variables*. The **space** occupied by a **variable** is defined by its
**dimensions** and their metadata. Dimensions are by definition
*one-dimensional* (i.e. an atomic vector in R of length 1 or more), an array with coordinate metadata, units,
type and interpretation. The **space** of a variable is defined as one or more
of the dimensions in the file. A given variable won't necessarily use all the
available dimensions and no dimensions are mandatory or particularly special.

NetCDF is very general, but it's quite common to see subcultures that rally around the way their particular domain's data are used and stored without encompassing very many other valid ways of using NetCDF. Tidync really tries to be as general as possible, sacrificing high level interpretations for lower-level control. 

## Tidync limitations

There are some limitations, specific to the tidync R package that are unrelated to the capabilities of the latest NetCDF library. 

No groups, a group can be specified by providing the group-within-a-source *as a source*. 

No compound types. 

No attribute metadata, coordinates of 1D axes are stored as *transform tables*, but coordinates of pairs (or higher sets) of axes are not explicitly linked to their array data.  

## Different kinds of NetCDF

NetCDF can be used to store *raster data*, and very commonly data is provided as a global grid of scientific data, here a snapshot of global ocean surface temperature generated by blending remote sensing, local observations and physical model output. 

There's an example file "reduced.nc" in the `stars` package, derived from the daily (OISSTV2 product)[https://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.highres.html]. 

We will explore the description of this source in detail to give an introduction to the tidync summary. 

```{r basic-raster}
oisstfile <- system.file("nc/reduced.nc", package = "stars")
```

To connect to this file we use `tidync()`. 

```{r basic-raster-connect}
oisst <- tidync(oisstfile)
```

*NB: this is not a real connection, like that used by ncdf4 or RNetCDF - tidync functions always open the file in read-only mode, extract information and/or data, and then close the open file connection.*

To see the available data in the file print a summmary of the source. 

```{r basic-raster-print}
print(oisst)
```

There are three kinds of information 

* one  (1) Data Source, our one file
* five (5) Grids, available *spaces* (or shapes) in the source 
* four (4) Dimensions, orthogonal axes from which Grids are composed

There is only one Grid available for multidimensional data, which is the first one "D0,D1,D2,D3" - all other Grids are one-dimensional. The 4D grid has four variables `sst`, `anom`, `ice`, and `err` and each 1D grid has a single variable. 

*NB: the 1D grids have a corresponding named dimension and name variable, making these "coordinate dimensions" see `coord_dim` in the Dimensions table, it's not necessarily true that a 1D grid will have a single 1D variable, it may have more than one variable, and it may only have an "index variable", i.e. no data values only the position `1:length(dimension)`.* 

The dimensions label, name, length, min and max value are seen in the Dimensions table and these values can never change, also see flags `unlim` (an unlimited dimension?) and `coord_dim`. 

The other Dimensions columns `start`, `count`, `dmin`, `dmax` apply when we slice into data variables with `hyper_filter()`. 

### Relationship to ncmeta

Tidync relies on the package [ncmeta](https://CRAN.r-project.org/) to extract information about NetCDF sources. There are functions to find available Grids, Dimensions and Attributes in ncmeta. 

Each grid has a name, size (ndims), and set of variables. Each grid is listed only once, which is an important pattern for each kind of entity when we are programming, the same applies to variables. See that there are 5 grids and 8 variables, with a row for each. 

```{r ncmeta-grids}
ncmeta::nc_grids(oisstfile)

ncmeta::nc_vars(oisstfile)
```

Some grids have more than one variable, so they are nested in the grid rows - use unnest to see all variables with their parent grid. 


```{r ncemeta-grids-expandvars}
ncmeta::nc_grids(oisstfile) %>% tidyr::unnest()
```

Similar functions exist for dimensions and variables. 

```{r ncmeta-dimensions-variables}
ncmeta::nc_dims(oisstfile)

ncmeta::nc_atts(oisstfile)
```

There are corresponding functions to find out more about individual variable`, dimensions and attributes by name or by internal index. 

```{r ncmeta-variable1}
ncmeta::nc_var(oisstfile, "anom")
ncmeta::nc_var(oisstfile, 5)

ncmeta::nc_dim(oisstfile, "lon")
ncmeta::nc_dim(oisstfile, 0)

ncmeta::nc_atts(oisstfile)
ncmeta::nc_atts(oisstfile, "time")

```

And we can find the internal metadata for each variable by expanding the value. 

```{r ncmeta-time-attributes}
ncmeta::nc_atts(oisstfile, "time") %>% tidyr::unnest()
```

With this information we may now apply the right interpretation to the time values

```{r ncmeta-time-atts}
tunit <- ncmeta::nc_atts(oisstfile, "time") %>% tidyr::unnest() %>% dplyr::filter(name == "units")
RNetCDF::utcal.nc(tunit$value, 1460)

## alternatively we can do this by hand
as.POSIXct("1978-01-01 00:00:00", tz = "UTC") + 1460 * 24 * 3600
```

and check that other independent systems provide the same information. 

```{r raster-stars}
raster::brick(oisstfile, varname = "anom")
stars::read_stars(oisstfile)
```

Tidync is *scared of doing this automatically for you*, but in combination the `ncmeta` package and `tidync` package provides the tools to program around the vagaries presented by NetCDF sources. 


### Degenerate dimensions

See that both `zlev` and `time` are listed as dimensions but have length 1, and also their min and max values are constants. The `zlev` tells us that this grid exists at elevation = 0 (the sea surface) and `time` that the data applies to `time = 1460`, the time is not expressed as a duration (though it presumably applies to the entire day). These are *degenerate dimensions*, i.e. the data is really 2D but we have a record of a 4D space from which they are expressed as a slice. This can cause problems as we would usually treat this data as a matrix in R, and so the `ncdf` and `RNetCDF` functions have arguments that are analogous to R's array indexing argument `drop = TRUE`, if we encounter a dimension of length 1 then drop it. Tidync will also drop dimensions by default when reading data, see `drop` argument in `?hyper_array`. 

### Reading the OISST data

At this point only metadata has been read, so let's read some sea surface temperatures already!

The fastest way to get all the data is to call the function `hyper_array`, this is the lowest level and is very close to using the `ncdf4` or `RNetCDF` package directly. 

```{r read-data}
(oisst_data <- oisst %>% hyper_array())
```

What happened there? We got a classed object, `tidync_data` but this is just a list with arrays. 

```{r oisst-data}
length(oisst_data)
names(oisst_data)
dim(oisst_data[[1]])
image(oisst_data[[1]])
```

This is exactly the data data provided by `ncdf4::ncvar_get()` or `RNetCDF::var.get.nc()` but we can do it in a single line of code. 

```{r oisst-data-single-line}
oisst_data <- tidync(oisstfile) %>% hyper_array()
op <- par(mfrow = n2mfrow(length(oisst_data)))
pals <- c("YlOrRd", "viridis", "Grays", "Blues")
for (i in seq_along(oisst_data)) {
  image(oisst_data[[i]], main = names(oisst_data)[i], col = hcl.colors(20, pals[i], rev = i ==1))
}
par(op)
```




time series raster "stars/nc/tos_O1_2001-2002.nc"

```{r time-series}
tos <- tidync(system.file("nc/tos_O1_2001-2002.nc", package = "stars"))
library(dplyr)
stos <- tos %>% hyper_filter(lon = between(lon, 140, 220), 
                     lat = between(lat, -60, 0)) %>% hyper_tibble()

library(ggplot2)
ggplot(stos, aes(lon, lat, fill = tos)) + facet_wrap(~tos)

```

curvi "ncmeta/extdata/guam.nc

Argo "rgdal/pictures/MR5905167_372.nc"

arbitrary "ncmeta/extdata/madishydro.nc"

geometry  - use the Durand fronts

## tidync verbs

Use a raster and the fronts (or Argo) to demonstrate. 

### tidync

### activate, active

## hyper_filter 

### hyper_array

## hyper_tibble

## hyper_tbl_cube



## Transforms concept for dimensions

Affine degeneracy

## Use with tidyverse

## Attributes aren't fully exposed

ncmeta::nc_atts

